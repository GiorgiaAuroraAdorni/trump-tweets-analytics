{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HkZdhEEJRt9a"
   },
   "source": [
    "# **Data Analytics**\n",
    "------\n",
    "\n",
    "## Sentiment Analysis Lab\n",
    "\n",
    "\n",
    "Take the **TRUMP** tweets and create your analytics:\n",
    "\n",
    "\n",
    "*   When Trump wishes the Olympic team good luck, he’s tweeting\n",
    "from his iPhone.\n",
    "*   When he’s insulting a rival, he’s usually tweeting from an Android.\n",
    "\n",
    "Make your analytics!\n",
    "\n",
    "*Is this an artifact showing which tweets are Trump’s own and which\n",
    "are by some handler? Any other insights?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NHO2PR-_xKeH"
   },
   "source": [
    "### Hint\n",
    "\n",
    "Control for instance:\n",
    "* Number of tweets from Android/iPhone\n",
    "* Most frequent positive and words\n",
    "* Sentiment dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Giorgia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Giorgia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from afinn import Afinn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import string\n",
    "from nltk import wordpunct_tokenize\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(stop_words=None, lowercase=True, max_features=5000)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression()\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KUoNxVnwxQx-"
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/nprapps/trump-tweet-analysis/master/data/since-20170120.json'\n",
    "trump_df = pd.read_json(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1030,
     "status": "ok",
     "timestamp": 1555313296789,
     "user": {
      "displayName": "Giorgia Adorni",
      "photoUrl": "https://lh3.googleusercontent.com/-iA8UNRAjDUo/AAAAAAAAAAI/AAAAAAAACRw/cgK9JHOlPvI/s64/photo.jpg",
      "userId": "15536769322585327683"
     },
     "user_tz": -120
    },
    "id": "vb_dqTIE5L25",
    "outputId": "a6379092-78ac-4bf4-9bd6-20e0ab900245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "4575\n"
     ]
    }
   ],
   "source": [
    "print(type(trump_df))\n",
    "print(len(trump_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>id_str</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-01 02:40:23</td>\n",
       "      <td>21996</td>\n",
       "      <td>1035718986871320576</td>\n",
       "      <td>False</td>\n",
       "      <td>5540</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Still can’t believe that Bloomberg violated a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-01 02:36:57</td>\n",
       "      <td>18946</td>\n",
       "      <td>1035718119459893248</td>\n",
       "      <td>False</td>\n",
       "      <td>3885</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Great day in North Carolina where Republicans ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-01 02:35:28</td>\n",
       "      <td>20129</td>\n",
       "      <td>1035717747936768000</td>\n",
       "      <td>False</td>\n",
       "      <td>5164</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>The ABC/Washington Post Poll was by far the le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-01 02:25:38</td>\n",
       "      <td>21855</td>\n",
       "      <td>1035715271418413056</td>\n",
       "      <td>False</td>\n",
       "      <td>5717</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>.@Rasmussen_Poll just came out at 48% approval...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-01 00:01:21</td>\n",
       "      <td>31907</td>\n",
       "      <td>1035678961349668864</td>\n",
       "      <td>False</td>\n",
       "      <td>8506</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>https://t.co/c79zLeREOA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-08-31 22:07:25</td>\n",
       "      <td>34220</td>\n",
       "      <td>1035650292782653440</td>\n",
       "      <td>False</td>\n",
       "      <td>9169</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>“President Donald J. Trump is Strengthening Re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at  favorite_count               id_str  is_retweet  \\\n",
       "0 2018-09-01 02:40:23           21996  1035718986871320576       False   \n",
       "1 2018-09-01 02:36:57           18946  1035718119459893248       False   \n",
       "2 2018-09-01 02:35:28           20129  1035717747936768000       False   \n",
       "3 2018-09-01 02:25:38           21855  1035715271418413056       False   \n",
       "4 2018-09-01 00:01:21           31907  1035678961349668864       False   \n",
       "5 2018-08-31 22:07:25           34220  1035650292782653440       False   \n",
       "\n",
       "   retweet_count              source  \\\n",
       "0           5540  Twitter for iPhone   \n",
       "1           3885  Twitter for iPhone   \n",
       "2           5164  Twitter for iPhone   \n",
       "3           5717  Twitter for iPhone   \n",
       "4           8506  Twitter for iPhone   \n",
       "5           9169  Twitter for iPhone   \n",
       "\n",
       "                                                text  \n",
       "0  Still can’t believe that Bloomberg violated a ...  \n",
       "1  Great day in North Carolina where Republicans ...  \n",
       "2  The ABC/Washington Post Poll was by far the le...  \n",
       "3  .@Rasmussen_Poll just came out at 48% approval...  \n",
       "4                            https://t.co/c79zLeREOA  \n",
       "5  “President Donald J. Trump is Strengthening Re...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1555313474148,
     "user": {
      "displayName": "Giorgia Adorni",
      "photoUrl": "https://lh3.googleusercontent.com/-iA8UNRAjDUo/AAAAAAAAAAI/AAAAAAAACRw/cgK9JHOlPvI/s64/photo.jpg",
      "userId": "15536769322585327683"
     },
     "user_tz": -120
    },
    "id": "ZOjAF4PL5MB7",
    "outputId": "25123fa4-3273-443f-bba0-0f87dbd2be17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Still can’t believe that Bloomberg violated a ...\n",
       "1    Great day in North Carolina where Republicans ...\n",
       "2    The ABC/Washington Post Poll was by far the le...\n",
       "3    .@Rasmussen_Poll just came out at 48% approval...\n",
       "4                              https://t.co/c79zLeREOA\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = trump_df['text']\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of tweets from Android/iPhone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RFh5_aSH5MHZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets from iPhone:  4134\n",
      "Number of tweets from Android:  174\n"
     ]
    }
   ],
   "source": [
    "tweets_iphone = trump_df[trump_df.source == 'Twitter for iPhone'].apply(pd.to_numeric, errors='coerce')\n",
    "print('Number of tweets from iPhone: ', len(text_iphone))\n",
    "\n",
    "tweets_android = trump_df[trump_df.source == 'Twitter for Android'].apply(pd.to_numeric, errors='coerce')\n",
    "print('Number of tweets from Android: ', len(tweets_android))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U8F50OQm5MPy"
   },
   "source": [
    "## Most frequent positive and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "    if lowercase:\n",
    "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "# Function to get the counter\n",
    "def get_counter(df):\n",
    "    sentences = (list(itertools.chain(df)))\n",
    "    flat_list = [item for sublist in sentences for item in sublist]\n",
    "    c = Counter(flat_list)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Still, can, ’, t, believe, that, Bloomberg, v...\n",
       "1       [Great, day, in, North, Carolina, where, Repub...\n",
       "2       [The, ABC, /, Washington, Post, Poll, was, by,...\n",
       "3       [., @Rasmussen_Poll, just, came, out, at, 48, ...\n",
       "4                               [https://t.co/c79zLeREOA]\n",
       "5       [“, President, Donald, J, ., Trump, is, Streng...\n",
       "6       [Wow, ,, I, made, OFF, THE, RECORD, COMMENTS, ...\n",
       "7       [I, will, be, doing, a, major, rally, for, Sen...\n",
       "8       [Thank, you, Indiana, ,, I, love, you, !, http...\n",
       "9       [Throwback, Thursday, !, #MAGA, https://t.co/8...\n",
       "10      [Kevin, Stitt, ran, a, great, winning, campaig...\n",
       "11      [CNN, is, working, frantically, to, find, thei...\n",
       "12      [Will, be, going, to, Evansville, ,, Indiana, ...\n",
       "13      [I, am, very, excited, about, the, person, who...\n",
       "14      [The, Rigged, Russia, Witch, Hunt, did, not, c...\n",
       "15      [Wow, ,, Nellie, Ohr, ,, Bruce, Ohr, ’, s, wif...\n",
       "16      [I, am, very, excited, about, the, person, who...\n",
       "17      [The, only, thing, James, Comey, ever, got, ri...\n",
       "18      [Ivanka, Trump, &, amp, ;, Jared, Kushner, had...\n",
       "19      [The, news, from, the, Financial, Markets, is,...\n",
       "20      [I, just, cannot, state, strongly, enough, how...\n",
       "21      [What, ’, s, going, on, at, @CNN, is, happenin...\n",
       "22      [The, hatred, and, extreme, bias, of, me, by, ...\n",
       "23      [Watch, :, Kanye, West, Says, Trump, Wants, to...\n",
       "24      [., ., ., charge, of, the, FISA, court, ., He,...\n",
       "25      [“, Ohr, told, the, FBI, it, (, the, Fake, Dos...\n",
       "26      [“, Lanny, Davis, admits, being, anonymous, so...\n",
       "27      [CNN, is, being, torn, apart, from, within, ba...\n",
       "28      [., ., ., of, money, on, joint, U, ., S, ., -,...\n",
       "29      [., ., ., differences, ,, they, will, be, reso...\n",
       "                              ...                        \n",
       "4545    [I, will, be, making, my, Supreme, Court, pick...\n",
       "4546    [even, ,, those, registered, to, vote, who, ar...\n",
       "4547    [I, will, be, asking, for, a, major, investiga...\n",
       "4548    [Big, day, planned, on, NATIONAL, SECURITY, to...\n",
       "4549    [If, Chicago, doesn't, fix, the, horrible, \", ...\n",
       "4550    [Congratulations, to, @FoxNews, for, being, nu...\n",
       "4551    [Great, meeting, with, Ford, CEO, Mark, Fields...\n",
       "4552    [Signing, orders, to, move, forward, with, the...\n",
       "4553    [Great, meeting, with, automobile, industry, l...\n",
       "4554    [A, photo, delivered, yesterday, that, will, b...\n",
       "4555    [Will, be, meeting, at, 9, :, 00, with, top, a...\n",
       "4556    [Busy, week, planned, with, a, heavy, focus, o...\n",
       "4557    [Peaceful, protests, are, a, hallmark, of, our...\n",
       "4558    [Wow, ,, television, ratings, just, out, :, 31...\n",
       "4559    [Watched, protests, yesterday, but, was, under...\n",
       "4560    [Had, a, great, meeting, at, CIA, Headquarters...\n",
       "4561    [RT, @WhiteHouse, :, \", Do, not, allow, anyone...\n",
       "4562    [A, fantastic, day, and, evening, in, Washingt...\n",
       "4563    [THANK, YOU, for, another, wonderful, evening,...\n",
       "4564    [TO, ALL, AMERICANS, 🇺, 🇸, https://t.co/D7Es6i...\n",
       "4565    [So, to, all, Americans, ,, in, every, city, n...\n",
       "4566    [It, is, time, to, remember, that, ., ., ., ht...\n",
       "4567    [We, will, follow, two, simple, rules, :, BUY,...\n",
       "4568    [We, will, bring, back, our, jobs, ., We, will...\n",
       "4569    [The, forgotten, men, and, women, of, our, cou...\n",
       "4570    [January, 20, th, 2017,, will, be, remembered,...\n",
       "4571    [What, truly, matters, is, not, which, party, ...\n",
       "4572    [power, from, Washington, ,, D, ., C, ., and, ...\n",
       "4573    [Today, we, are, not, merely, transferring, po...\n",
       "4574    [It, all, begins, today, !, I, will, see, you,...\n",
       "Name: text, Length: 4575, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokening = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "tweets_tokenized = tweets.apply(tokening.tokenize)\n",
    "\n",
    "# Stopword removal\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "tweets_tokenized_stop = tweets_tokenized.apply(lambda x: [item for item in x if item not in stop])\n",
    "tweets_tokenized_stop\n",
    "\n",
    "# Punctuaction removal\n",
    "punctuation = string.punctuation\n",
    "tweets_tokenized_stop_punct = tweets_tokenized_stop.apply(lambda x: [item for item in x if item not in punctuation])\n",
    "\n",
    "sentences = (list(itertools.chain(tweets_tokenized_stop_punct)))\n",
    "flat_list = [item for sublist in sentences for item in sublist]\n",
    "flat_list\n",
    "\n",
    "c = Counter(flat_list)\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7PTolfUD5MUc"
   },
   "source": [
    "## Sentiment dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JG7f4dvy5Mae"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2DuiHgrJ5MMj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Laboratorio4_SentimentAnalysis_Lab.ipynb",
   "provenance": [
    {
     "file_id": "1zx06s1ZDlF4AjUV3nqdkup093DRSVf_z",
     "timestamp": 1555311736196
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
